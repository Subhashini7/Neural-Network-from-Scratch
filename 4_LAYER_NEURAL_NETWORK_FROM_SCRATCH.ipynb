{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NEURAL NETWORK FROM SCRATCH"
      ],
      "metadata": {
        "id": "nJoEbUuUFA5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a 4-layer neural network using Numpy,Tensorflow and Python"
      ],
      "metadata": {
        "id": "WylKPTcoFH2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Choosing a dataset***"
      ],
      "metadata": {
        "id": "ZKVuLc0gFLNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will import MINST dataset and using that as the input to our deep neural"
      ],
      "metadata": {
        "id": "HdWKTQNHFPWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyQcD9dlFUOY",
        "outputId": "e150e7af-5b6e-4323-d005-370632312335"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhgv8te_FTHz",
        "outputId": "a8e06fcf-d943-4d21-ea46-bf42b0ec4e3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Fetch the dataset\n",
        "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "# Normalize the pixel values\n",
        "x = (x / 255).astype('float32')\n",
        "\n",
        "# Convert labels from strings to integers\n",
        "y = y.astype(int)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y = to_categorical(y)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.15, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvjhw5lVFY3D",
        "outputId": "9bbb1c35-ffbc-4d27-909e-218f2f15ceac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4-Layer Neural Network with NumPy"
      ],
      "metadata": {
        "id": "qiargFWoFjW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "class DeepNeuralNetwork:\n",
        "    def __init__(self, sizes, epochs=10, l_rate=0.001):\n",
        "        self.sizes = sizes\n",
        "        self.epochs = epochs\n",
        "        self.l_rate = l_rate\n",
        "\n",
        "        # We save all parameters in the neural network in this dictionary\n",
        "        self.params = self.initialization()\n",
        "\n",
        "    def sigmoid(self, x, derivative=False):\n",
        "        if derivative:\n",
        "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def softmax(self, x, derivative=False):\n",
        "        # Numerically stable with large exponentials\n",
        "        exps = np.exp(x - np.max(x))\n",
        "        if derivative:\n",
        "            s = exps / np.sum(exps, axis=0)\n",
        "            return s * (1 - s)\n",
        "        return exps / np.sum(exps, axis=0)\n",
        "\n",
        "    def initialization(self):\n",
        "        # number of nodes in each layer\n",
        "        input_layer = self.sizes[0]\n",
        "        hidden_1 = self.sizes[1]\n",
        "        hidden_2 = self.sizes[2]\n",
        "        output_layer = self.sizes[3]\n",
        "\n",
        "        params = {\n",
        "            'W1': np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
        "            'W2': np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
        "            'W3': np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
        "        }\n",
        "\n",
        "        return params\n",
        "\n",
        "    def forward_pass(self, x_train):\n",
        "        params = self.params\n",
        "\n",
        "        # Input layer activations become the sample\n",
        "        params['A0'] = x_train.astype(np.float32)\n",
        "\n",
        "        # Input layer to hidden layer 1\n",
        "        params['Z1'] = np.dot(params['W1'], params['A0'])\n",
        "        params['A1'] = self.sigmoid(params['Z1'])\n",
        "\n",
        "        # Hidden layer 1 to hidden layer 2\n",
        "        params['Z2'] = np.dot(params['W2'], params['A1'])\n",
        "        params['A2'] = self.sigmoid(params['Z2'])\n",
        "\n",
        "        # Hidden layer 2 to output layer\n",
        "        params['Z3'] = np.dot(params['W3'], params['A2'])\n",
        "        params['A3'] = self.softmax(params['Z3'])\n",
        "\n",
        "        return params['A3']\n",
        "\n",
        "    def backward_pass(self, y_train, output):\n",
        "        '''\n",
        "            This is the backpropagation algorithm, for calculating the updates\n",
        "            of the neural network's parameters.\n",
        "        '''\n",
        "        params = self.params\n",
        "        change_w = {}\n",
        "\n",
        "        # Calculate W3 update\n",
        "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
        "        change_w['W3'] = np.outer(error, params['A2'])\n",
        "\n",
        "        # Calculate W2 update\n",
        "        error = np.dot(params['W3'].T, error) * self.sigmoid(params['Z2'], derivative=True)\n",
        "        change_w['W2'] = np.outer(error, params['A1'])\n",
        "\n",
        "        # Calculate W1 update\n",
        "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
        "        change_w['W1'] = np.outer(error, params['A0'])\n",
        "\n",
        "        return change_w\n",
        "\n",
        "    def update_network_parameters(self, changes_to_w):\n",
        "        '''\n",
        "            Update network parameters according to update rule from\n",
        "            Stochastic Gradient Descent.\n",
        "        '''\n",
        "        for key, value in changes_to_w.items():\n",
        "            self.params[key] -= self.l_rate * value\n",
        "\n",
        "    def compute_accuracy(self, x_val, y_val):\n",
        "        '''\n",
        "            This function does a forward pass of x, then checks if the indices\n",
        "            of the maximum value in the output equals the indices in the label\n",
        "            y. Then it sums over each prediction and calculates the accuracy.\n",
        "        '''\n",
        "        predictions = []\n",
        "\n",
        "        for x, y in zip(x_val, y_val):\n",
        "            output = self.forward_pass(x)\n",
        "            pred = np.argmax(output)\n",
        "            predictions.append(pred == np.argmax(y))\n",
        "\n",
        "        return np.mean(predictions)\n",
        "\n",
        "    def train(self, x_train, y_train, x_val, y_val):\n",
        "        start_time = time.time()\n",
        "        for iteration in range(self.epochs):\n",
        "            for x, y in zip(x_train, y_train):\n",
        "                output = self.forward_pass(x)\n",
        "                changes_to_w = self.backward_pass(y, output)\n",
        "                self.update_network_parameters(changes_to_w)\n",
        "\n",
        "            accuracy = self.compute_accuracy(x_val, y_val)\n",
        "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
        "                iteration+1, time.time() - start_time, accuracy * 100\n",
        "            ))\n",
        "\n"
      ],
      "metadata": {
        "id": "FIM9mr9KFdsp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Results***"
      ],
      "metadata": {
        "id": "ghqL8ffTFywL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completely dependent on how the weights are initialized, we get different results. Sometimes we are stuck at 0% accuracy, sometimes 5-10%, other times it jumps from 22% to 94.5%. If you want to experiment, try using a seed for numpy by `np.random.seed(42)` or any other number. Then you should get the same results each time. `Inline code`"
      ],
      "metadata": {
        "id": "tzpBYfcXF6JY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mnist\n",
        "!pip install tensorflow\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load MNIST dataset using Keras\n",
        "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Convert all arrays to float32 to ensure compatibility\n",
        "x_train = x_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "x_val = x_val.astype(np.float32)\n",
        "y_val = y_val.astype(np.float32)\n",
        "\n",
        "# Flatten the image data to a single dimension (28x28 to 784)\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "x_val = x_val.reshape(-1, 784)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
        "\n",
        "dnn = DeepNeuralNetwork(sizes=[784, 128, 64, 10])\n",
        "dnn.train(x_train, y_train, x_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Infln214F8cU",
        "outputId": "4ad8e7a9-e329-4625-a1ec-e5c9b5f8c310"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mnist) (1.26.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3e1622461ab5>:15: RuntimeWarning: overflow encountered in square\n",
            "  return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
            "<ipython-input-6-3e1622461ab5>:16: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n",
            "<ipython-input-6-3e1622461ab5>:15: RuntimeWarning: overflow encountered in exp\n",
            "  return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
            "<ipython-input-6-3e1622461ab5>:15: RuntimeWarning: invalid value encountered in divide\n",
            "  return (np.exp(-x))/((np.exp(-x)+1)**2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Time Spent: 58.89s, Accuracy: 9.80%\n",
            "Epoch: 2, Time Spent: 110.74s, Accuracy: 9.80%\n",
            "Epoch: 3, Time Spent: 164.93s, Accuracy: 9.80%\n",
            "Epoch: 4, Time Spent: 227.78s, Accuracy: 9.80%\n",
            "Epoch: 5, Time Spent: 308.95s, Accuracy: 9.80%\n",
            "Epoch: 6, Time Spent: 366.96s, Accuracy: 9.80%\n",
            "Epoch: 7, Time Spent: 423.12s, Accuracy: 9.80%\n",
            "Epoch: 8, Time Spent: 478.40s, Accuracy: 9.80%\n",
            "Epoch: 9, Time Spent: 531.47s, Accuracy: 9.80%\n",
            "Epoch: 10, Time Spent: 584.20s, Accuracy: 9.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch"
      ],
      "metadata": {
        "id": "YvBke1IiG73D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading MNIST dataset with pyTorch"
      ],
      "metadata": {
        "id": "G34189bDHHxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.1307,), (0.3081,))\n",
        "            ])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True, transform=transform))\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transform))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_YIdtP4F-vu",
        "outputId": "140e7a56-6c1d-4969-b316-621d0b0f4567"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 29576812.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 899567.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 7282936.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3191577.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4-layer Neural Network with pytorch"
      ],
      "metadata": {
        "id": "MW-VdnOzHNUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, epochs=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.linear1 = nn.Linear(784, 128)\n",
        "        self.linear2 = nn.Linear(128, 64)\n",
        "        self.linear3 = nn.Linear(64, 10)\n",
        "\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def forward_pass(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = self.linear2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        x = self.linear3(x)\n",
        "        x = torch.softmax(x, dim=0)\n",
        "        return x\n",
        "\n",
        "    def one_hot_encode(self, y):\n",
        "        encoded = torch.zeros([10], dtype=torch.float64)\n",
        "        encoded[y[0]] = 1.\n",
        "        return encoded\n",
        "\n",
        "    def train(self, train_loader, optimizer, criterion):\n",
        "        start_time = time.time()\n",
        "        loss = None\n",
        "\n",
        "        for iteration in range(self.epochs):\n",
        "            for x,y in train_loader:\n",
        "                y = self.one_hot_encode(y)\n",
        "                optimizer.zero_grad()\n",
        "                output = self.forward_pass(torch.flatten(x))\n",
        "                loss = criterion(output, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            print('Epoch: {0}, Time Spent: {1:.2f}s, Loss: {2}'.format(\n",
        "                iteration+1, time.time() - start_time, loss\n",
        "            ))"
      ],
      "metadata": {
        "id": "nXQulTcRHRPK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model.train(train_loader, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijogmAPSHbjt",
        "outputId": "36ba5e52-8ea7-4f16-f823-c1e12fc8bcb7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Time Spent: 106.74s, Loss: 0.733536759763956\n",
            "Epoch: 2, Time Spent: 208.85s, Loss: 0.733870442211628\n",
            "Epoch: 3, Time Spent: 313.31s, Loss: 0.7341575577855111\n",
            "Epoch: 4, Time Spent: 414.67s, Loss: 0.7344085946679115\n",
            "Epoch: 5, Time Spent: 531.90s, Loss: 0.7346328251063824\n",
            "Epoch: 6, Time Spent: 640.99s, Loss: 0.7348380081355572\n",
            "Epoch: 7, Time Spent: 745.80s, Loss: 0.7350303806364537\n",
            "Epoch: 8, Time Spent: 853.56s, Loss: 0.7352157883346081\n",
            "Epoch: 9, Time Spent: 960.11s, Loss: 0.7354001797735691\n",
            "Epoch: 10, Time Spent: 1064.04s, Loss: 0.7355900779366493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tensorflow 2.0 with keras"
      ],
      "metadata": {
        "id": "ObPD625WKfMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV6qGW3vI4qM",
        "outputId": "0389bd72-be02-4ce6-8d3f-354a8d347ebd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "XgD4giS3KlU9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_val, y_val) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "y_train = to_categorical(y_train)"
      ],
      "metadata": {
        "id": "mkmA1H-FKobk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='sigmoid'),\n",
        "    Dense(64, activation='sigmoid'),\n",
        "    Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='SGD',\n",
        "              loss=BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3tvYwd7Kreo",
        "outputId": "cad9330c-b87c-44ac-99f7-bdf51a37b7b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.2804 - loss: 0.9254\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3876 - loss: 1.2635\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1017 - loss: 6.6720\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1037 - loss: 6.6729\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 6.6728\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1024 - loss: 6.6691\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.1021 - loss: 6.6643\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1018 - loss: 6.6777\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1040 - loss: 6.6695\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1020 - loss: 6.6723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78cd04e13fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fOroailxNR2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}